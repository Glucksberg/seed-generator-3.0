# Seed Generator 3.0

Gerador de mnemonics BIP39 otimizado com processamento paralelo usando GPU (CUDA) e multiprocessamento.

## üìã Descri√ß√£o

Este script gera mnemonics BIP39 aleat√≥rios e busca por aqueles que atendem a um crit√©rio de contagem de caracteres. Utiliza processamento paralelo com m√∫ltiplos processos e aproveitamento de GPU quando dispon√≠vel para m√°xima performance.

## üöÄ Caracter√≠sticas

- **Processamento GPU**: Utiliza CUDA quando dispon√≠vel para gera√ß√£o r√°pida de entropia
- **Multiprocessamento**: M√∫ltiplos workers paralelos para gera√ß√£o de mnemonics
- **Fila otimizada**: Sistema de fila com ajuste din√¢mico de batch size
- **Interface colorida**: Sa√≠da colorida no terminal usando colorama
- **Logging**: Salva resultados em arquivo de log
- **Interrup√ß√£o segura**: Pressione 'q' e Enter para parar o script graciosamente

## üì¶ Requisitos

- Python 3.7 ou superior
- GPU NVIDIA com suporte CUDA (opcional, mas recomendado para melhor performance)
- CUDA Toolkit instalado (se usar GPU)

## üîß Instala√ß√£o

1. Clone o reposit√≥rio:
```bash
git clone <url-do-repositorio>
cd seed-generator-3.0
```

2. Instale as depend√™ncias:
```bash
pip install -r requirements.txt
```

### Instala√ß√£o do PyTorch com suporte CUDA (Opcional)

Se voc√™ tem uma GPU NVIDIA e quer aproveitar o processamento GPU, instale o PyTorch com suporte CUDA:

**Para CUDA 11.8:**
```bash
pip install torch --index-url https://download.pytorch.org/whl/cu118
```

**Para CUDA 12.1:**
```bash
pip install torch --index-url https://download.pytorch.org/whl/cu121
```

**Para CPU apenas:**
```bash
pip install torch
```

Verifique a vers√£o do seu CUDA antes de instalar:
```bash
nvcc --version
```

## üìñ Uso

### Uso B√°sico

Execute o script com os par√¢metros padr√£o:
```bash
python gpuseed3.py
```

### Par√¢metros Dispon√≠veis

- `--threshold`: Limite de caracteres para filtrar mnemonics (padr√£o: 45)
- `--count`: N√∫mero de mnemonics a encontrar por contagem de caracteres (padr√£o: 5)
- `--logfile`: Nome do arquivo de log (padr√£o: mnemonics_log.txt)
- `--batch-size`: Tamanho do batch para processamento GPU (padr√£o: 2048)

### Exemplos

Buscar mnemonics com 40 caracteres ou menos:
```bash
python gpuseed3.py --threshold 40
```

Encontrar 10 mnemonics por contagem de caracteres:
```bash
python gpuseed3.py --count 10
```

Usar batch size maior para melhor performance:
```bash
python gpuseed3.py --batch-size 4096
```

Combinar par√¢metros:
```bash
python gpuseed3.py --threshold 42 --count 3 --logfile resultados.txt --batch-size 4096
```

### Parar o Script

Para interromper o script de forma segura, pressione `q` e depois `Enter`.

## üìä Sa√≠da

O script exibe no console:
- Mnemonics encontrados que atendem ao crit√©rio
- Contagem total de caracteres
- N√∫mero de itera√ß√µes processadas
- Tempo decorrido
- Estat√≠sticas de processamento (mnemonics/s)

Os resultados tamb√©m s√£o salvos no arquivo de log especificado.

## ‚öôÔ∏è Configura√ß√µes Avan√ßadas

Voc√™ pode ajustar as constantes no in√≠cio do arquivo `gpuseed3.py`:

- `NUM_STREAMS`: N√∫mero de streams CUDA para processamento paralelo (padr√£o: 4)
- `QUEUE_MAX_SIZE`: Tamanho m√°ximo da fila (padr√£o: 50000)
- `WORKER_DELAY`: Delay base nos workers (padr√£o: 0.01)
- `QUEUE_WARNING_THRESHOLD`: Limite para desacelerar workers (padr√£o: 0.9)
- `BATCH_SIZE_MIN`: Tamanho m√≠nimo do batch (padr√£o: 512)

## üêõ Troubleshooting

### PyTorch n√£o detecta GPU

1. Verifique se o CUDA est√° instalado:
```bash
nvcc --version
```

2. Verifique se o PyTorch foi instalado com suporte CUDA:
```python
python -c "import torch; print(torch.cuda.is_available())"
```

3. Se retornar `False`, reinstale o PyTorch com suporte CUDA apropriado.

### Erro ao importar mnemonic

Certifique-se de que a biblioteca foi instalada corretamente:
```bash
pip install mnemonic
```

### Performance baixa

- Aumente o `--batch-size` se tiver GPU dispon√≠vel
- Verifique se est√° usando GPU (o script informa no in√≠cio)
- Ajuste o n√∫mero de processos conforme seu hardware

## üìù Notas

- O script usa multiprocessamento, ent√£o aproveita todos os cores dispon√≠veis
- A fila ajusta dinamicamente o batch size para evitar sobrecarga
- Os resultados s√£o salvos incrementalmente no arquivo de log
- Mnemonics duplicados s√£o automaticamente ignorados

## üìÑ Licen√ßa

[Especifique a licen√ßa do seu projeto aqui]

## ü§ù Contribuindo

Contribui√ß√µes s√£o bem-vindas! Sinta-se √† vontade para abrir issues ou pull requests.

