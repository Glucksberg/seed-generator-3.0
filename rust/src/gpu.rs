// GPU support module using RustaCUDA with cuRAND kernels
// Uses compiled CUDA kernels to generate random numbers directly on GPU
#[cfg(feature = "gpu")]
use rustacuda::prelude::*;
#[cfg(feature = "gpu")]
use rustacuda::memory::DeviceBuffer;
#[cfg(feature = "gpu")]
use rustacuda::function::Function;
#[cfg(feature = "gpu")]
use std::ffi::CString;
#[cfg(feature = "gpu")]
use std::cell::RefCell;

// Auto-generated module with embedded CUDA kernel PTX
// This module is generated by build.rs during compilation
#[cfg(feature = "gpu")]
mod kernel_ptx {
    include!(concat!(env!("OUT_DIR"), "/kernel_ptx.rs"));
}

// Thread-local storage for CUDA context, module, and kernels
// CUDA contexts are not Send/Sync, so we use thread-local storage
#[cfg(feature = "gpu")]
thread_local! {
    static GPU_THREAD_CONTEXT: RefCell<Option<ThreadGpuContext>> = RefCell::new(None);
}

#[cfg(feature = "gpu")]
struct ThreadGpuContext {
    _context: Context,
    module_and_kernels: Box<ModuleAndKernels>,
}

#[cfg(feature = "gpu")]
struct ModuleAndKernels {
    _module: Module,
    init_kernel: Function<'static>,
    gen_kernel: Function<'static>,
}

pub struct GpuContext {
    available: bool,
    // Note: CUDA Context and Stream are not Send/Sync
    // Each thread that needs GPU will create its own context
    // We only store availability flag here
}

impl GpuContext {
    pub fn new() -> Self {
        #[cfg(feature = "gpu")]
        {
            // Try to initialize CUDA
            match Self::init_cuda() {
                Ok(_) => {
                    println!("GPU initialized successfully (CUDA)");
                    Self {
                        available: true,
                    }
                }
                Err(e) => {
                    eprintln!("GPU initialization failed: {}. Falling back to CPU.", e);
                    Self {
                        available: false,
                    }
                }
            }
        }
        
        #[cfg(not(feature = "gpu"))]
        {
            Self {
                available: false,
            }
        }
    }
    
    #[cfg(feature = "gpu")]
    fn init_cuda() -> Result<(), rustacuda::error::CudaError> {
        // Initialize CUDA - just verify it works
        rustacuda::init(CudaFlags::empty())?;
        
        // Get the first device to verify CUDA is available
        let _device = Device::get_device(0)?;
        
        // Don't create context here - each thread will create its own
        Ok(())
    }
    
    pub fn is_available(&self) -> bool {
        self.available
    }
    
    #[cfg(feature = "gpu")]
    pub fn cleanup(&self) {
        // Cleanup thread-local GPU contexts
        // This forces destruction of CUDA contexts when shutting down
        GPU_THREAD_CONTEXT.with(|ctx_cell| {
            let mut ctx_opt = ctx_cell.borrow_mut();
            if ctx_opt.is_some() {
                // Drop the context explicitly
                *ctx_opt = None;
            }
        });
    }
    
    #[cfg(not(feature = "gpu"))]
    pub fn cleanup(&self) {
        // No-op when GPU is not enabled
    }
    
    #[cfg(feature = "gpu")]
    fn init_thread_context() -> Result<ThreadGpuContext, String> {
        // Initialize CUDA if not already initialized (ignore error if already initialized)
        let _ = rustacuda::init(CudaFlags::empty());
        
        let device = Device::get_device(0)
            .map_err(|e| format!("Failed to get device: {}", e))?;
        
        // Create CUDA context (only once per thread)
        static INIT_LOGGED: std::sync::atomic::AtomicBool = std::sync::atomic::AtomicBool::new(false);
        let is_first_init = !INIT_LOGGED.swap(true, std::sync::atomic::Ordering::Relaxed);
        
        if is_first_init {
            eprintln!("[GPU] Initializing thread-local CUDA context...");
        }
        
        let context = Context::create_and_push(
            ContextFlags::MAP_HOST | ContextFlags::SCHED_AUTO,
            device
        ).map_err(|e| {
            eprintln!("[GPU] ERROR: Failed to create context: {}", e);
            format!("Failed to create context: {}", e)
        })?;
        
        if is_first_init {
            eprintln!("[GPU] CUDA context created successfully");
        }
        
        // Load compiled CUDA kernel PTX (embedded at compile time)
        let ptx_content = kernel_ptx::KERNEL_PTX;
        
        if ptx_content.is_empty() {
            eprintln!("[GPU] ERROR: CUDA kernel PTX is empty. Kernel was not compiled during build.");
            eprintln!("[GPU] Rebuild with: cargo build --release --features gpu");
            return Err("CUDA kernel PTX not available. Make sure CUDA Toolkit is installed and kernel was compiled successfully.".to_string());
        }
        
        let ptx = CString::new(ptx_content)
            .map_err(|e| format!("Invalid PTX string: {}", e))?;
        
        // Load module from PTX
        let module = Module::load_from_string(ptx.as_c_str())
            .map_err(|e| {
                eprintln!("[GPU] ERROR: Failed to load CUDA module: {}", e);
                format!("Failed to load CUDA module: {}", e)
            })?;
        
        // Get kernel functions
        let init_func_name = CString::new("init_curand_states")
            .map_err(|e| format!("Invalid function name: {}", e))?;
        let gen_func_name = CString::new("generate_random_bytes")
            .map_err(|e| format!("Invalid function name: {}", e))?;
        
        let init_kernel = module.get_function(init_func_name.as_c_str())
            .map_err(|e| {
                eprintln!("[GPU] ERROR: Failed to get init_curand_states function: {}", e);
                format!("Failed to get init_curand_states function: {}", e)
            })?;
        let gen_kernel = module.get_function(gen_func_name.as_c_str())
            .map_err(|e| {
                eprintln!("[GPU] ERROR: Failed to get generate_random_bytes function: {}", e);
                format!("Failed to get generate_random_bytes function: {}", e)
            })?;
        
        // SAFETY: We need to transmute the Functions to 'static before moving the module
        // This is safe because we ensure the module lives as long as the functions
        // by storing them together in the same struct
        let init_kernel_static: Function<'static> = unsafe { std::mem::transmute(init_kernel) };
        let gen_kernel_static: Function<'static> = unsafe { std::mem::transmute(gen_kernel) };
        
        // Now we can move the module since we've already transmuted the functions
        let module_and_kernels = Box::new(ModuleAndKernels {
            _module: module,
            init_kernel: init_kernel_static,
            gen_kernel: gen_kernel_static,
        });
        
        Ok(ThreadGpuContext {
            _context: context,
            module_and_kernels,
        })
    }
    
    #[cfg(feature = "gpu")]
    pub fn generate_entropy_batch(&self, size: usize) -> Result<Vec<[u8; 16]>, String> {
        if !self.available {
            return Err("GPU not available".to_string());
        }
        
        // Get or initialize thread-local GPU context
        GPU_THREAD_CONTEXT.with(|ctx_cell| {
            let mut ctx_opt = ctx_cell.borrow_mut();
            
            // Initialize if not already initialized
            if ctx_opt.is_none() {
                *ctx_opt = Some(Self::init_thread_context()?);
            }
            
            let ctx = ctx_opt.as_ref().unwrap();
            
            // Allocate memory for cuRAND states (48 bytes per state)
            // cuRAND state size is typically 48 bytes
            const CURAND_STATE_SIZE: usize = 48;
            let states_size = size * CURAND_STATE_SIZE;
            let mut curand_states = DeviceBuffer::from_slice(&vec![0u8; states_size])
                .map_err(|e| format!("Failed to allocate cuRAND states: {}", e))?;
            
            // Initialize cuRAND states with random seed
            let seed = std::time::SystemTime::now()
                .duration_since(std::time::UNIX_EPOCH)
                .unwrap()
                .as_nanos() as u64;
            
            // Create a CUDA stream for kernel execution
            let stream = Stream::new(StreamFlags::NON_BLOCKING, None)
                .map_err(|e| format!("Failed to create CUDA stream: {}", e))?;
            
            let grid_size = (size as u32 + 255) / 256; // 256 threads per block
            let block_size = (256u32, 1u32, 1u32);
            let grid_dim = (grid_size, 1u32, 1u32);
            let shared_mem_bytes = 0u32;
            
            // Get references to kernels for use in launch! macro
            let init_kernel = &ctx.module_and_kernels.init_kernel;
            let gen_kernel = &ctx.module_and_kernels.gen_kernel;
            
            // Launch init kernel using the launch! macro (rustacuda 0.1 API)
            static KERNEL_LAUNCH_LOGGED: std::sync::atomic::AtomicBool = std::sync::atomic::AtomicBool::new(false);
            let is_first_launch = !KERNEL_LAUNCH_LOGGED.swap(true, std::sync::atomic::Ordering::Relaxed);
            
            if is_first_launch {
                eprintln!("[GPU] Launching init kernel (grid: {:?}, block: {:?})", grid_dim, block_size);
            }
            
            unsafe {
                launch!(init_kernel<<<grid_dim, block_size, shared_mem_bytes, stream>>>(
                    curand_states.as_device_ptr(),
                    seed,
                    size as i32
                ))
                    .map_err(|e| {
                        eprintln!("[GPU] ERROR: Failed to launch init kernel: {}", e);
                        format!("Failed to launch init kernel: {}", e)
                    })?;
            }
            
            if is_first_launch {
                eprintln!("[GPU] Init kernel launched successfully");
            }
            
            // Allocate output buffer on GPU
            let total_bytes = size * 16;
            let mut output_buffer = DeviceBuffer::from_slice(&vec![0u8; total_bytes])
                .map_err(|e| format!("Failed to allocate output buffer: {}", e))?;
            
            // Generate random bytes using cuRAND kernel
            if is_first_launch {
                eprintln!("[GPU] Launching generation kernel");
            }
            
            unsafe {
                launch!(gen_kernel<<<grid_dim, block_size, shared_mem_bytes, stream>>>(
                    curand_states.as_device_ptr(),
                    output_buffer.as_device_ptr(),
                    size as i32
                ))
                    .map_err(|e| {
                        eprintln!("[GPU] ERROR: Failed to launch generation kernel: {}", e);
                        format!("Failed to launch generation kernel: {}", e)
                    })?;
            }
            
            if is_first_launch {
                eprintln!("[GPU] Generation kernel launched successfully");
            }
            
            // Synchronize stream to ensure kernels complete
            if is_first_launch {
                eprintln!("[GPU] Synchronizing CUDA stream...");
            }
            
            stream.synchronize()
                .map_err(|e| {
                    eprintln!("[GPU] ERROR: Failed to synchronize CUDA stream: {}", e);
                    format!("Failed to synchronize CUDA stream: {}", e)
                })?;
            
            if is_first_launch {
                eprintln!("[GPU] CUDA stream synchronized successfully");
            }
            
            // Copy results back to CPU
            if is_first_launch {
                eprintln!("[GPU] Copying results from GPU to CPU...");
            }
            
            let mut cpu_data = vec![0u8; total_bytes];
            output_buffer.copy_to(&mut cpu_data)
                .map_err(|e| {
                    eprintln!("[GPU] ERROR: Failed to copy results from GPU: {}", e);
                    format!("Failed to copy results from GPU: {}", e)
                })?;
            
            if is_first_launch {
                eprintln!("[GPU] Results copied successfully ({} bytes)", total_bytes);
            }
            
            // Convert to Vec<[u8; 16]>
            let mut result = Vec::with_capacity(size);
            for i in 0..size {
                let mut entropy = [0u8; 16];
                entropy.copy_from_slice(&cpu_data[i * 16..(i + 1) * 16]);
                result.push(entropy);
            }
            
            Ok(result)
        })
    }
    
    #[cfg(not(feature = "gpu"))]
    pub fn generate_entropy_batch(&self, _size: usize) -> Result<Vec<[u8; 16]>, String> {
        Err("GPU support not compiled. Rebuild with --features gpu".to_string())
    }
}

// IMPLEMENTATION NOTE:
// This implementation uses compiled CUDA kernels with cuRAND to generate random numbers
// directly on the GPU, providing true GPU acceleration.
//
// The kernel is compiled during build.rs and loaded at runtime.
// cuRAND states are initialized once per batch and reused for generation.
